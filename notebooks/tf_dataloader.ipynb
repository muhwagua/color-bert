{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_dataloader.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM8OGWDqFxTAyI2K3TpVEjg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"IjNaCgCjVuld"},"source":["!git clone https://github.com/muhwagua/color-bert.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PeyA51hXsqqZ"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqYh7T1leVH8","executionInfo":{"status":"ok","timestamp":1616562075543,"user_tz":-540,"elapsed":33995,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}}},"source":["import random\n","import re\n","import urllib.request\n","\n","from tensorflow.keras.utils import Sequence\n","import tensorflow as tf\n","from transformers import (\n","    BertConfig,\n","    BertForMaskedLM,\n","    BertTokenizer,\n",")\n","from argparse import Namespace"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omLT00VNhTPk","executionInfo":{"status":"ok","timestamp":1616562076047,"user_tz":-540,"elapsed":34060,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"ba6dbbec-5267-4f57-f2c8-532aab43213b"},"source":["txt_url = \"https://raw.githubusercontent.com/muhwagua/color-bert/main/data/all.txt\"\n","urllib.request.urlretrieve(txt_url, 'train.txt')"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('train.txt', <http.client.HTTPMessage at 0x7f89e645edd0>)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"rjdES9cZh7jl","executionInfo":{"status":"ok","timestamp":1616562955516,"user_tz":-540,"elapsed":490,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}}},"source":["args = Namespace()\n","args.train = \"train.txt\"\n","args.max_len = 128\n","args.model_name = \"bert-base-uncased\"\n","args.batch_size = 4\n","args.color_ratio = 0.5"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JY3vmHni97z","executionInfo":{"status":"ok","timestamp":1616562176986,"user_tz":-540,"elapsed":73666,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}}},"source":["tokenizer = BertTokenizer.from_pretrained(args.model_name)\n","\n","\n","class MaskedLMDataset(Sequence):\n","    def __init__(self, file, color_ratio, tokenizer, masking):\n","        self.tokenizer = tokenizer\n","        self.color_ratio = color_ratio\n","        self.masking = masking\n","        self.lines = self.load_lines(file)\n","        self.masked = self.all_mask(self.lines, self.color_ratio)\n","        self.ids = self.encode_lines(self.lines, self.masked, masking)\n","\n","\n","    def load_lines(self, file):\n","        with open(file) as f:\n","            lines = [\n","                line\n","                for line in f.read().splitlines()\n","                if (len(line) > 0 and not line.isspace())\n","            ]\n","        return lines\n","\n","\n","    def color_mask(self, line, masking=True):\n","        colors = [\n","        \"red\",\n","        \"orange\",\n","        \"yellow\",\n","        \"green\",\n","        \"blue\",\n","        \"purple\",\n","        \"brown\",\n","        \"white\",\n","        \"black\",\n","        \"pink\",\n","        \"lime\",\n","        \"gray\",\n","        \"violet\",\n","        \"cyan\",\n","        \"magenta\",\n","        \"khaki\",\n","    ]\n","        for color in colors:\n","            match = re.search(f\"(\\s|^){color}(\\s|[.!?\\\\-])\", line)\n","            if match:\n","                global start, end\n","                (start, end) = random.choice([match.span()])\n","        return line[: start + 1] + \"[MASK]\" + line[end - 1 :]\n","    \n","\n","    def random_mask(self, line, masking=True):\n","        words = line.split()\n","        mask_idx = random.choice(range(len(words)))\n","        words[mask_idx] = \"[MASK]\"\n","        return \" \".join(words)  \n","\n","\n","    def all_mask(self, lines, color_ratio, masking=True):\n","        masked = []\n","        for line in lines:\n","            coin = random.random()  \n","            if coin > color_ratio:\n","                masked.append(self.random_mask(line))\n","            else:\n","                masked.append(self.color_mask(line))\n","        \n","        return masked\n","\n","\n","    def encode_lines(self, lines, masked, masking):\n","        if masking == True:\n","            batch_encoding = self.tokenizer.batch_encode_plus(masked, \n","                return_attention_mask=False,return_token_type_ids=False,padding=True,truncation=True,\n","                max_length=args.max_len\n","            )\n","            return batch_encoding[\"input_ids\"]\n","\n","        elif masking == False:\n","            batch_encoding =self.tokenizer.batch_encode_plus(lines, \n","                return_attention_mask=False,return_token_type_ids=False,padding=True,truncation=True,\n","                max_length=args.max_len\n","            )\n","            return batch_encoding[\"input_ids\"]\n","\n","\n","    def __len__(self):\n","        return len(self.lines)\n","    \n","    \n","    def __getitem__(self, idx):\n","        return self.ids[idx]\n","\n","\n","train_dataset = MaskedLMDataset(args.train, args.color_ratio, tokenizer, masking=True)\n","label_dataset = MaskedLMDataset(args.train, args.color_ratio, tokenizer, masking=False)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqZPJ2VkdIgb"},"source":["class Dataloader(Sequence):\n","\n","    def __init__(self, x_set, y_set, batch_size, shuffle):\n","        self.x, self.y = x_set, y_set\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.tpu, self.strategy, self.global_batch_size = self.connect_TPU(self.batch_size)\n","        self.dist_dataset = self.distributed_dataset(self.x, self.y, self.global_batch_size, shuffle)\n","\n","\n","    def connect_TPU(self, batch_size):\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","\n","        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","        global_batch_size = batch_size * strategy.num_replicas_in_sync\n","\n","        return tpu, strategy, global_batch_size\n","\n","\n","    def distributed_dataset(self, x, y, global_batch_size, shuffle):\n","        dataset_x = tf.data.Dataset.from_tensor_slices(self.x)\n","        dataset_y = tf.data.Dataset.from_tensor_slices(self.y)\n","        dataset = tf.data.Dataset.zip((dataset_x, dataset_y))\n","        AUTO = tf.data.experimental.AUTOTUNE\n","        if shuffle == True:\n","            dataset = dataset.shuffle(len(self.x)).repeat()\n","\n","        dataset = dataset.batch(global_batch_size).prefetch(AUTO)    \n","        dist_dataset = self.strategy.experimental_distribute_dataset(dataset)\n","\n","        return dist_dataset\n","\n","\n","prepareTPU = Dataloader(train_dataset, label_dataset, batch_size=16, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-pSrjAQsahN","executionInfo":{"status":"ok","timestamp":1616563289717,"user_tz":-540,"elapsed":572,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}}},"source":["Tpu, Strategy, GlobalBatchSize = prepareTPU.tpu, prepareTPU.strategy, prepareTPU.global_batch_size\n","dist_dataset =  prepareTPU.dist_dataset"],"execution_count":48,"outputs":[]}]}